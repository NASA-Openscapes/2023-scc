{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-denmark",
   "metadata": {},
   "source": [
    "# [Accessing Cloud Optimized GeoTIFF (COG) - S3 Direct Access](https://openscapes.2i2c.cloud/hub/user-redirect/lab/tree/2022-Fall-ECOSTRESS-Cloud-Workshop/how-tos/data_access/Earthdata_Cloud__Single_File__Direct_S3_Access_Clip_COG_Example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-junction",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we will access data for the ECOSTRESS Tiled Land Surface Temperature and Emissivity Instantaneous L2 Global 70 m V002 data product. These data are archived and distributed as Cloud Optimized GeoTIFF (COG) files, one file for each variable.\n",
    "\n",
    "We will access a single COG file, Land Surface Temperature (LST), from inside the AWS cloud (us-west-2 region, specifically) and load it into Python as an `xarray` `dataarray`. This approach leverages S3 native protocols for efficient access to the data.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "### 1. AWS instance running in us-west-2\n",
    "\n",
    "NASA Earthdata Cloud data in S3 can be directly accessed via temporary credentials; this access is limited to requests made within the US West (Oregon) (code: us-west-2) AWS region.\n",
    "\n",
    "### 2. Earthdata Login\n",
    "\n",
    "An Earthdata Login account is required to access data from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n",
    "\n",
    "### 3. netrc File\n",
    "\n",
    "You will need a netrc file containing your NASA Earthdata Login credentials in order to execute the notebooks. A netrc file can be created manually within text editor and saved to your home directory. For additional information see: [Authentication for NASA Earthdata](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/04_NASA_Earthdata_Authentication.html#authentication-via-netrc-file).\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- how to retrieve temporary S3 credentials for in-region direct S3 bucket access\n",
    "- how to perform in-region direct access of ECOSTRESS Cloud Optimized geoTIFF (COG) files in S3\n",
    "- how to plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-audience",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-antarctica",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "import boto3\n",
    "from osgeo import gdal\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from pyproj import Proj\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "gv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-wrist",
   "metadata": {},
   "source": [
    "## Get Temporary AWS Credentials\n",
    "\n",
    "Direct S3 access is achieved by passing NASA supplied temporary credentials to AWS so we can interact with S3 objects from applicable Earthdata Cloud buckets. For now, each NASA DAAC has different AWS credentials endpoints. Below are some of the credential endpoints to various DAACs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_cred_endpoint = {\n",
    "    'podaac':'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
    "    'gesdisc': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
    "    'lpdaac':'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials',\n",
    "    'ornldaac': 'https://data.ornldaac.earthdata.nasa.gov/s3credentials',\n",
    "    'ghrcdaac': 'https://data.ghrc.earthdata.nasa.gov/s3credentials'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0db410-9b9a-4380-be7c-90ed54a00b1e",
   "metadata": {},
   "source": [
    "Create a function to make a request to an endpoint for temporary credentials. Remember, each DAAC has their own endpoint and credentials are not usable for cloud data from other DAACs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_creds(provider):\n",
    "    return requests.get(s3_cred_endpoint[provider]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_creds_req = get_temp_creds('lpdaac')\n",
    "#temp_creds_req"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-integration",
   "metadata": {},
   "source": [
    "## Workspace Environment Setup\n",
    "\n",
    "For this exercise, we are going to open up a context manager for the notebook using the rasterio.env module to store the required GDAL and AWS configurations we need to access the data in Earthdata Cloud. While the context manager is open (rio_env.__enter__()) we will be able to run the open or get data commands that would typically be executed within a with statement, thus allowing us to more freely interact with the data. We’ll close the context (rio_env.__exit__()) at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd4773-c2d8-4999-9142-d7d2b3cd6491",
   "metadata": {},
   "source": [
    "Create a `boto3` Session object using your temporary credentials. This Session is used to pass credentials and configuration to AWS so we can interact wit S3 objects from applicable buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89c7c5-6cda-476b-9258-ed78a4b780f9",
   "metadata": {},
   "source": [
    "GDAL environment variables must be configured to access COGs in Earthdata Cloud. Geospatial data access Python packages like rasterio and rioxarray depend on GDAL, leveraging GDAL’s “Virtual File Systems” to read remote files. GDAL has a lot of environment variables that control it’s behavior. Changing these settings can mean the difference being able to access a file or not. They can also have an impact on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='TRUE',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae86f5f-354c-4ede-b3c6-622fb4f737e0",
   "metadata": {},
   "source": [
    "In this example we're interested in the ECOSTRESS Tiled Land Surface Temperature and Emissivity data collection from NASA's [LP DAAC](https://lpdaac.usgs.gov/) in Earthdata Cloud. Below we specify the S3 URL to the data asset in Earthdata Cloud. This URL can be found via [Earthdata Search](../tutorials/Earthdata_search.md) or programmatically through the [CMR](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/01_Data_Discovery_CMR.html) and [CMR-STAC](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html) APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_url = 's3://lp-prod-protected/HLSL30.020/HLS.L30.T10SGD.2020272T183449.v2.0/HLS.L30.T10SGD.2020272T183449.v2.0.B04.tif'\n",
    "s3_url_lst = 's3://lp-prod-protected/ECO_L2T_LSTE.002/ECOv002_L2T_LSTE_24479_001_11SKU_20221030T092522_0710_01/ECOv002_L2T_LSTE_24479_001_11SKU_20221030T092522_0710_01_LST.tif'\n",
    "s3_url_qa = 's3://lp-prod-protected/ECO_L2T_LSTE.002/ECOv002_L2T_LSTE_24479_001_11SKU_20221030T092522_0710_01/ECOv002_L2T_LSTE_24479_001_11SKU_20221030T092522_0710_01_QC.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacb14f-fce2-42c2-ac2a-c6c20c4c5152",
   "metadata": {},
   "source": [
    "## Direct In-region Access\n",
    "\n",
    "Read in the ECOSTRESS Tiles LST S3 URL into our workspace using `rioxarray`, an extension of `xarray` used to read geospatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = rioxarray.open_rasterio(s3_url_lst, chunks='auto')\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc636c0-1405-4d74-a403-5087488addbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = rioxarray.open_rasterio(s3_url_qa, chunks='auto')\n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd63c7-ec5d-4582-9672-5067d14488e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LST_dataset = xr.Dataset({'LST': da, 'quality': qa})\n",
    "LST_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78752272-d939-4e20-8ef7-cc6950a4baf1",
   "metadata": {},
   "source": [
    "The file is read into Python as an `xarray` `dataarray` with a **band**, **x**, and **y** dimension. In this example the **band** dimension is meaningless, so we'll use the `squeeze()` function to remove **band** as a dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst = LST_dataset.squeeze('band', drop=True)\n",
    "da_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f9202-b96b-4782-9b0f-128aba681cf7",
   "metadata": {},
   "source": [
    "Plot the `dataarray`, representing the LST, using `hvplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst['LST'].hvplot.image(x = 'x', y = 'y', crs = 'EPSG:32610', cmap='jet', rasterize=False, tiles='EsriImagery', width=800, height=600, colorbar=True, title = 'Land Surface Temperature')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa87db8-4df6-4445-8981-ab08672f2b75",
   "metadata": {},
   "source": [
    "## Define the Region of Interest for Clipping\n",
    "\n",
    "We'll read in our GeoJSON file of our points of interest and create bounding box that contains a points coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07854a-b5b4-46dc-8b50-19e722e87221",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = geopandas.read_file('../../tutorials/landcover.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2652ff3-523c-49a8-9ae1-a28bf2efb1f6",
   "metadata": {},
   "source": [
    "Extract the min/max values for the y and x axis     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c6efa-fbe8-4afe-8976-b14615e1720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minx, miny, maxx, maxy = field.geometry.total_bounds\n",
    "minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78cb8f-c2f3-4b0d-8609-0580b2a6e0c6",
   "metadata": {},
   "source": [
    "Order the coordinates for the bounding box counterclockwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b352ce5-c161-45f4-abbb-0e566b7c9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [\n",
    "    (minx, miny),\n",
    "    (maxx, miny),\n",
    "    (maxx, maxy),\n",
    "    (minx, maxy)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430120f2-9f23-4e63-997d-257171f144c0",
   "metadata": {},
   "source": [
    "Create a shapely polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f85ef8-25fa-4a90-a6e3-527c093bb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_shape = Polygon(coords)\n",
    "feature_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be39f70-573b-499c-87c7-b88719081a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gv.tile_sources.EsriImagery.opts(width=700, height=500)\n",
    "farmField = gv.Polygons(feature_shape).opts(line_color='yellow', line_width=10, color=None)\n",
    "base * farmField "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6712a6-5306-41d3-9297-34ecdb8cdc4b",
   "metadata": {},
   "source": [
    "Let's take a look at the bounding coordinate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3eb78a-c435-4ea0-a02f-ad7177443534",
   "metadata": {},
   "source": [
    "Note, the values above are in decimal degrees and represent the longitude and latitude for the lower left corner and upper right corner respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151ba1c-67e9-42ef-8796-889bce2b0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_shape.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8754c-c9dd-40e3-9b45-35685a359d0d",
   "metadata": {},
   "source": [
    "Get the projection information from the ECOSTRESS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af2872-5c94-47fa-a59e-f3e92aa283fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_proj = da_lst.rio.crs\n",
    "src_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c730e6-7be3-49fe-bfa7-3a69aab2be47",
   "metadata": {},
   "source": [
    "Transform coordinates from lat lon (units = dd) to UTM (units = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ac045-b080-4860-9442-40f7955f3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_CRS = Proj('+proj=longlat +datum=WGS84 +no_defs', preserve_units=True)   # Source coordinate system of the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9983bd-c70b-4f3a-90a6-f62c8572da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = pyproj.Transformer.from_proj(geo_CRS, src_proj)                    # Set up the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1ba79-474f-45dd-b5a4-40382af3b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsUTM = transform(project.transform, feature_shape)\n",
    "fsUTM.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b907617-68c5-4ba3-b299-313341b53059",
   "metadata": {},
   "source": [
    "The coordinates for our feature have now been converted to source raster projection. Note the difference in the values between `feature_shape.bounds` (in geographic) and `fsUTM.bounds` (in UTM projection).\n",
    "\n",
    "Now we can clip our ECOSTRESS LST file to our region of insterest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bcdb8-e628-41c8-a96b-bf2d73aa34b8",
   "metadata": {},
   "source": [
    "## Access and clip the ECOSTRESS LST COG\n",
    "\n",
    "We can now use our transformed ROI bounding box to clip the ECOSTRESS S3 object we accessed before. We'll use the `rio.clip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f42fd0-e628-4785-b447-f3695778608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst_clip = rioxarray.open_rasterio(s3_url_lst, chunks='auto').squeeze('band', drop=True).rio.clip([fsUTM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83aaa45-1cf6-44bb-ab9f-b29ece55a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a457cb6-059a-4900-ab20-367a46139f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst_clip.hvplot.image(x = 'x', y = 'y', crs = 'EPSG:32610', cmap='jet', rasterize=False, width=800, height=600,title = 'Land Surface Temperature (Kelvin)', colorbar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c875b38-64bc-4841-ab96-8f17478e4872",
   "metadata": {},
   "source": [
    "Exit the context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "rio_env.__exit__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75be23e-e035-4f78-8acb-ee9806dc9df7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9ad36-2b28-4cd5-8029-29f5bf9c17b6",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Direct S3 Data Access with rioxarray](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/05_Data_Access_Direct_S3.html)\n",
    "\n",
    "[Direct_S3_Access__gdalvrt](https://github.com/NASA-Openscapes/2021-Cloud-Hackathon/blob/main/tutorials/Additional_Resources__Direct_S3_Access__gdalvrt.ipynb)\n",
    "\n",
    "[Direct_S3_Access__rioxarray_clipping](https://github.com/NASA-Openscapes/2021-Cloud-Hackathon/blob/main/tutorials/Additional_Resources__Direct_S3_Access__rioxarray_clipping.ipynb)\n",
    "\n",
    "[Getting Started with Cloud-Native Harmonized Landsat Sentinel-2 (HLS) Data in R](https://lpdaac.usgs.gov/resources/e-learning/getting-started-with-cloud-native-harmonized-landsat-sentinel-2-hls-data-in-r/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
