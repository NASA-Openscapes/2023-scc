{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516b723a-2c3f-46a7-95d7-420e7d2d4999",
   "metadata": {},
   "source": [
    "# Using `icepyx` to access ICESat-2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d85ef2-5ed9-4bf6-b086-cd440a43c2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install icepyx==0.8.1 -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b723884-afa0-44ba-bb86-fa909f2399d2",
   "metadata": {},
   "source": [
    "## What is ICESat-2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433a7b7-a1c3-4079-9b6f-150869d6241b",
   "metadata": {},
   "source": [
    "![IS2](https://icesat-2.gsfc.nasa.gov/sites/default/files/MissionLogo_0.png)\n",
    "\n",
    "ICESat-2 carries a satellite lidar instrument, ATLAS. Lidar is an active remote sensing technique in which pulses of light are emitted and the return time is used to measure distance. The available ICESat-2 data products range from sea ice freeboard to land elevation to cloud backscatter characteristics. A list of availble products can be found [here](https://icesat-2.gsfc.nasa.gov/science/data-products). In this tutorial we will look at the `ATL08` Land Water Vegetation Elevation product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6e1db-ac0a-4ab3-88d2-8557e58ba616",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "ICESat-2 measures data along 3 strong/weak beam pairs, resulting in 3 strong beams and 3 weak beams. The strong and weak beams are calibrated such that the weak beams have more sensitivity to viewing very bright surfaces (Ex. ice), while the strong beams are able to view surfaces with lower reflectances (Ex. water). The beams are designated in each data product as `gt1l`, `gt1r`, `gt2l`, `gt2r`, `gt3l`, and `gt3r`, where `gt` stands for \"ground track\", the number refers to the photon emitter, and the `l` and `r` indicate \"left\" or \"right\" beam of the pair. Which of these designations is strong or weak depends on the orientation of the satellite (forwards, `sc_orient==1`; backwards, `sc_orient==0`). A helpful table of which beams are strong/weak can be found on p131 of the [ATL03 Algorithm Theoretical Basis Document](https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf). The ATLAS spot number (values 1-6) is based on the ground track designation (`gt1l` etc.) and spacecraft orientation and, once determined can be used to consistently identify strong (Spots 1, 3, and 5) and weak (Spots 2, 4, and 6) beams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19109b-12ed-4353-8f99-9fccf0cb4394",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Tracks](https://ars.els-cdn.com/content/image/1-s2.0-S0034425718305066-gr1.jpg)\n",
    "\n",
    "Photo: Neuenschwander et. al. 2019, Remote Sens. Env. [DOI](https://doi.org/10.1016/j.rse.2018.11.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025aa5c-8b14-47e3-9468-d7ae184fc568",
   "metadata": {},
   "source": [
    "### Counting Photons\n",
    "\n",
    "The ICESat-2 lidar collects at the single photon level, different from most commercial lidar systems. A lot of additional photons get returned as solar background noise, and removing these unwanted photons is a key part of the algorithms that produce the higher level data products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c634e4-3197-4413-9e9c-57890014c296",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\".images/ATL08_signalphotons.jpg\" width=450/>\n",
    "\n",
    "> _Fig. 2. Results from signal finding methods for simulated ATLAS data. Black points show raw point cloud data as ingested from ATL03 product. Blue points overlaid in each plot show which photons each method identified as signal. Top panel reflects the signal photons as identified on the ATL03 data product (medium and high confidence signal photons). Bottom panel reflects the signal photons identified from the ATL08 DRAGANN method._ (Neuenschwander & Pitts, 2019)\n",
    "Photo: Neuenschwander et. al. 2019, Remote Sens. Env. [DOI](https://doi.org/10.1016/j.rse.2018.11.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f2392-5b0c-4410-a9a4-67c1f152b15b",
   "metadata": {},
   "source": [
    "To aggregate all these photons into more manegable chunks ATL08 consolidates the photons into 100m segments, each made up of five 20m segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32d452-c417-4038-acfd-908a82210e23",
   "metadata": {},
   "source": [
    "## What is `icepyx`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7739d-b5c4-4182-be84-87b8e80dc302",
   "metadata": {},
   "source": [
    "<img src=\"https://icepyx.readthedocs.io/en/latest/_static/icepyx_v2_oval_orig_nobackgr.png\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c70aa7-14ee-4375-a178-850fa5fc943b",
   "metadata": {},
   "source": [
    "icepyx is a community and software library for searching, downloading, and reading ICESat-2 data. While opening data should be straightforward, there are some oddities in navigating the highly nested organization and hundreds of variables of the ICESat-2 data. icepyx provides tools to help with those oddities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf385f8-a63d-418b-ba16-93d032a4172b",
   "metadata": {},
   "source": [
    "### Fitting icepyx into the data access package landscape\n",
    "\n",
    "For ICESat-2 data, the icepyx package can:\n",
    "- search for available data granules (data files)\n",
    "- order and download data\n",
    "- order a subset of data: clipped in space, time, containing fewer variables, or a few other options provided by NSIDC\n",
    "- provides functionality to search through the available data variables\n",
    "- read ICESat-2 data into xarray DataArrays, including merging data from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7417fa-3807-42ac-a296-47aa7543a7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import icepyx as ipx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928c4e8-e9c6-4ed2-a92f-139f0d2b243d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape, GeometryCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eea118-1a77-48c8-804e-78a877730d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41605f-83c3-448a-8285-72f3ef39b4e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using icepyx to search for data\n",
    "\n",
    "We won't dive into using icepyx to search for and download data in this tutorial, since we already discussed how to do that with `earthaccess`. The code to search and download is still provided below for the curious reader. The [icepyx documentation](https://icepyx.readthedocs.io/en/latest/example_notebooks/IS2_data_access.html) shows more detail about different search parameters and how to inspect the results of a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa7597-092f-4fa4-8292-c5aa62838baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open a geojson of our area of interest\n",
    "with open(\"bosque_primavera.json\") as f:\n",
    "    features = json.load(f)[\"features\"]\n",
    "\n",
    "bosque = GeometryCollection([shape(feature[\"geometry\"]).buffer(0) for feature in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa29ac9-9fd5-445e-bb69-7dc6818a68f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use our search parameters to setup a search Query\n",
    "short_name = 'ATL08'\n",
    "spatial_extent = list(bosque.bounds)\n",
    "date_range = ['2019-05-04','2019-05-04']\n",
    "region = ipx.Query(short_name, spatial_extent, date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f263f-1615-4afc-a0cd-d6fcdfa16de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display if any data files, or granules, matched our search\n",
    "region.avail_granules(ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d59565-0276-473f-ae6f-daab9068f563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the granules to a into a folder called 'bosque_primavera_ATL08'\n",
    "region.download_granules('./bosque_primavera_ATL08')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96f73b-1f81-4f94-9b8b-0f7b8872fe0d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> If you don't want to type your earthdata login information every time they are\n",
    "    required you can setup more automatic methods of authentication. Two common methods\n",
    "    are 1) Add your earthdata password and username to as environment variables\n",
    "    as EARTHDATA_USERNAME and EARTHDATA_PASSWORD. 2) setup a .netrc file in your home directory. See <a href=\"https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/04_NASA_Earthdata_Authentication.html\"> the Openscapes tutorial</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c2881-5f2c-40f3-a7b5-c871e6fa32a3",
   "metadata": {},
   "source": [
    "## Reading a file with icepyx\n",
    "\n",
    "To read a file with icepyx there are several steps:\n",
    "1. Create a `Read` object. This sets up an initial connection to your file(s) and validates the metadata.\n",
    "2. Tell the `Read` object what variables you would like to read\n",
    "3. Load your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ad78c-235d-4476-9f78-c0f2efce41eb",
   "metadata": {},
   "source": [
    "### Create a `Read` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e1cf9-f604-48b5-b761-6d374d0e2389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern = \"processed_ATL{product:2}_{datetime:%Y%m%d%H%M%S}_{rgt:4}{cycle:2}{orbitsegment:2}_{version:3}_{revision:2}.h5\"\n",
    "reader = ipx.Read('./bosque_primavera_ATL08', \"ATL08\", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5e7cd-da71-4a12-8d22-8467ba740270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a54014-7a55-4536-8bd4-e85510bc30b3",
   "metadata": {},
   "source": [
    "### Select your variables\n",
    "\n",
    "To view the variables contained in your dataset you can call `.vars` on your data reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac93cf-5114-43ca-8c69-d27393116741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader.vars.avail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c6b6a-99bf-457d-b6d6-d113e92c0e46",
   "metadata": {},
   "source": [
    "Thats **a lot** of variables!\n",
    "\n",
    "One key feature of icepyx is the ability to browse the variables available in the dataset. There are typically hundreds of variables in a single dataset, so that is a lot to sort through! Let's take a moment to get oriented to the organization of ATL08 variables, by first a few important pieces of the algorithm.\n",
    "\n",
    "To create higher level variables like canopy or terrain height, the ATL08 algorithms goes through a series of steps:\n",
    "1. Identify signal photons from noise photons\n",
    "2. Classify each of the signal photons as either terrain, canopy, or canopy top\n",
    "3. Remove elevation, so the heights are with respect to the ground\n",
    "3. Group the signal photons into 100m segments. If there are a sufficient number of photons in that group, calculate statistics for terrain and canopy (ex. mean height, max height, standard deviation, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc8bcc-cbc8-4a6e-9437-1d557d6ee9d3",
   "metadata": {},
   "source": [
    "<img src=\".images/ATL08_photon_classification_example.jpg\" width=450/>\n",
    "\n",
    "> _Fig. 4. An example of the classified photons produced from the ATL08 algorithm. Ground photons (red dots) are labeled as all photons falling within a point spread function distance of the estimated ground surface. The top of canopy photons (green dots) are photons that fall within a buffer distance from the upper canopy surface, and the photons that lie between the top of canopy surface and ground surface are labeled as canopy photons (blue dots)._ (Neuenschwander & Pitts, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e92d5-fbd7-4f8f-b05e-667ace36de1e",
   "metadata": {},
   "source": [
    "Providing all the potentially useful information from all these processing steps results in a data file that looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69615cf-f1cc-4a48-8ea9-b99be5365101",
   "metadata": {},
   "source": [
    "<img src=\".images/ATL08_structure.png\" width=650/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a308de6-4400-4324-9177-cc87890fc3f8",
   "metadata": {},
   "source": [
    "Another way to visualize these structure is to download one file and open it using https://myhdf5.hdfgroup.org/. \n",
    "\n",
    "Further information about each one of the variables is available in the [Algorithm Theoretical Basis Document (ATBD)](https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf) for ATL08."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028faf6-6626-415c-99f5-522863691ef2",
   "metadata": {},
   "source": [
    "There is lots to explore in these variables, but we will move forward using a common ATL08 variable: `h_canopy`, or the \"98% height of all the individual relative canopy heights (height above terrain)\" (ATBD definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bd099-3dab-4613-907b-d538726b28f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader.vars.append(var_list=['h_canopy', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641232cf-1e8a-4144-ab06-33510d6cc1c0",
   "metadata": {},
   "source": [
    "Note that adding variables is a required step before you can load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2202b5-67d0-461d-b8fe-73569f5f9bd3",
   "metadata": {},
   "source": [
    "### Load the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c134a7-9ba3-48f0-9d8a-e5e6473ff49a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = reader.load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c85a2-e967-437c-9f90-2aabeb87559a",
   "metadata": {},
   "source": [
    "Here we have an xarray Dataset, a common Python data structure for analysis. To visualize the data we can plot it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47231a-697f-4c2f-bcf7-d53351e1b7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.plot.scatter(x=\"longitude\", y=\"latitude\", hue=\"h_canopy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5c10e-f422-4eb6-9d37-9aad740e28f9",
   "metadata": {},
   "source": [
    "Notice also that the data is shown for just our area of interest! That is because of icepyx's subsetting feature, which we will discuss more in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b35f3a-975f-405d-8115-917bfffa1bfe",
   "metadata": {},
   "source": [
    "## Using icepyx to download a subset of a granule\n",
    "\n",
    "One feature which is not yet available in earthaccess is the ability to download just a subset of the file. This could mean a smaller spatial area or fewer variables. This feature is available in icepyx.\n",
    "\n",
    "We saw above that icepyx by default will subset your data to the bounding box you provided when downloading. If you know in advance which variables you want icepyx can also subset variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10368c6b-da93-41c7-b40b-59ca03a9f6e2",
   "metadata": {},
   "source": [
    "### Subset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538688f-00d1-447c-a5e2-8bb47140965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Query\n",
    "short_name = 'ATL08'\n",
    "spatial_extent = list(bosque.bounds)\n",
    "date_range = ['2019-05-04','2019-05-04']\n",
    "region = ipx.Query(short_name, spatial_extent, date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f82c65-778b-47aa-9ea1-8ee87d84846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify desired variables\n",
    "region.order_vars.append(var_list=['h_canopy', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83121ad-f9fa-4373-9cb6-90708c73693c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the granules, using the Coverage kwarg to specify variables\n",
    "region.download_granules(path='./ATL08_h_canopy', Coverage=region.order_vars.wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488dbb2-6c00-42ad-b53b-7d3856c20751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the new data\n",
    "pattern = \"processed_ATL{product:2}_{datetime:%Y%m%d%H%M%S}_{rgt:4}{cycle:2}{orbitsegment:2}_{version:3}_{revision:2}.h5\"\n",
    "reader = ipx.Read('./ATL08_h_canopy', \"ATL08\", pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad34a5e-3422-4d7e-bb65-653f6d059964",
   "metadata": {},
   "source": [
    "The available variables list on the subset dataset is a lot shorter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69fa49-1dc2-4bca-a4d1-e2bffab778b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.vars.avail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f9bc9-a9b8-41f4-ac1f-d889b692c011",
   "metadata": {},
   "source": [
    "## Some example plots\n",
    "\n",
    "In this last section there are a few more examples of selecting ATL08 variables and plotting them to view the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e64ea2-ae03-4919-9119-874b85345154",
   "metadata": {},
   "source": [
    "### Example 1: View the photon classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16717d91-f92d-4bb7-b484-1700e82fec84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the data reader\n",
    "pattern = \"processed_ATL{product:2}_{datetime:%Y%m%d%H%M%S}_{rgt:4}{cycle:2}{orbitsegment:2}_{version:3}_{revision:2}.h5\"\n",
    "reader = ipx.Read('./bosque_primavera_ATL08', \"ATL08\", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933518f6-6b5f-4238-b272-d1fe305ad5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the photon height and classification variables\n",
    "reader.vars.append(var_list=['ph_h', 'classed_pc_flag', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf76063-c502-40fe-9930-4518b8a639b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "ds_photons = reader.load()\n",
    "ds_photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13264c27-da5d-4061-abec-467dbf5bbdab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ds_photons.plot.scatter(ax=ax, x='delta_time', y='ph_h', hue='classed_pc_flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca56951-0711-43c7-9d0f-065c2ae2228c",
   "metadata": {},
   "source": [
    "### Plot the canopy compared to the ground height\n",
    "\n",
    "A nice idea, but there are a few places where the ground may be above the canopy. Not sure how to talk about that. Maybe consider if h_te_best_fit is the best variable to use for height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bcd53-0457-4906-beb8-946fef1cf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove our previous variables\n",
    "reader.vars.remove(all=True)\n",
    "# Add the next set of variables to the list\n",
    "reader.vars.append(var_list=['h_te_best_fit', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cfb1c-6408-411c-8f87-e5040898149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ds_te = reader.load()\n",
    "ds_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40ee7a-890a-4f54-9ceb-7809b301ca17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 3)\n",
    "\n",
    "# plot the canopy height above ground level\n",
    "(ds.h_canopy + ds_te.h_te_best_fit).plot.scatter(ax=ax, x=\"delta_time\", y=\"h_canopy\") # orange\n",
    "\n",
    "# plot the terrain values\n",
    "ds_te.plot.scatter(ax=ax, x=\"delta_time\", y=\"h_te_best_fit\") # blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e0e9a-6ca2-4f06-884c-ec82382708ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19665c3-98be-486c-9313-1a5a76a96122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c784a-46bf-4c4e-87c5-979179fc0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84231c-bfa3-4c1e-9113-0fce7170f5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc5163-7242-497b-a48b-cb62c5ff1d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad502ba4-7402-4922-9258-2299c9af7fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc67228-d603-4529-99bb-7aec7a674e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f607425-91c9-428d-99f8-faeef8d0d9e3",
   "metadata": {},
   "source": [
    "## Other ideas for a fun last thing but will likely get dropped \n",
    "\n",
    "Trying to come up with a fun final plot, if there is time. Ignore this for now and revisit in the morning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f599912-571a-45d7-8b6a-b5c35cff1aa4",
   "metadata": {},
   "source": [
    "### Add more of a basemap to the spatial plot\n",
    "\n",
    "Cartopy doesn't seem to have any nice built in basemaps, and I think foluim would be too complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2f3ac-d7ab-4e69-83f4-fa90877d495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Add background features\n",
    "ax.add_feature(cfeature.COASTLINE, alpha=0.3)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "# ax.set_extent([-77.5, -75.4, 36.6, 39.7])\n",
    "\n",
    "# Add and format gridlines. Remove top and right labels\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.2, linestyle='--')\n",
    "gl.top_labels, gl.right_labels = False, False\n",
    "\n",
    "ds.plot.scatter(ax=ax, x=\"longitude\", y=\"latitude\", hue=\"h_canopy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02bb8c-4718-466d-8d9d-eadb4e19833e",
   "metadata": {},
   "source": [
    "Notice that the data is already subset to our area of interest! (Also download the full granule with earthaccess to compare the area?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b2338-8e97-4c28-a04c-6e9803e0bbbd",
   "metadata": {},
   "source": [
    "### Interactive plot with holoviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ca0c3-d8c7-4619-8077-9f7b5b169447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f699f30-269b-4005-ad99-0d1ff14a9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hvplot.scatter(y=\"h_canopy\", x=\"latitude\",\n",
    "                  by=['spot', 'photon_idx', 'gran_idx'], legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7bd33-50df-4ce2-adb2-e706f49410d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b4ec9-29dc-46e3-bd4b-057253f643e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt1l = ds.where(ds.gt == 'gt1l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d820ee1-701b-4ef5-bc55-b72674cde940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
